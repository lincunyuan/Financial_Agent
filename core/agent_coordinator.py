# ä¸»Agentåè°ƒï¼ˆæµç¨‹æ§åˆ¶ä¸LLMäº¤äº’ï¼‰
from typing import Dict, Optional, List
from utils.logging import default_logger as logger
from core.session_manager import RedisSessionManager, build_context_prompt
from core.knowledge_base import FinancialKnowledgeBase
from core.tool_integration import FinancialDataAPI, add_source_citations
from core.llm_client import LLMClient
from utils.config_loader import default_config_loader

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from core.session_manager import RedisSessionManager
from core.knowledge_base import FinancialKnowledgeBase
from core.tool_integration import FinancialDataAPI, add_source_citations
from core.llm_client import LLMClient
from utils.config_loader import default_config_loader

# å¯¼å…¥æ–°å¢çš„æ™ºèƒ½æ¨¡å—
from core.intent_recognizer import IntentRecognizer
from core.prompt_engine import PromptEngine
from core.data_processor import DataProcessor
from utils.text_processing import insert_current_time, format_prompt_with_context

class FinancialAssistantAgent:
    def __init__(self, config_dir: str = "config"):
        """åˆå§‹åŒ–Agentç»„ä»¶"""
        self.config_loader = default_config_loader
        
        # åŠ è½½æ•°æ®åº“é…ç½®
        db_config = self.config_loader.load_config("database.yaml")
        
        # åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
        redis_host = self.config_loader.get("database.yaml", "redis.host", "localhost")
        redis_port = self.config_loader.get("database.yaml", "redis.port", 6379)
        self.session_manager = RedisSessionManager(host=redis_host, port=redis_port)
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        mysql_config = self.config_loader.get("database.yaml", "mysql", {})
        self.knowledge_base = FinancialKnowledgeBase(
            mysql_host=mysql_config.get("host", "localhost"),
            mysql_user=mysql_config.get("user", "root"),
            mysql_password=mysql_config.get("password", ""),
            mysql_db=mysql_config.get("database", "financial_rag")
        )
        
        # åˆå§‹åŒ–æ•°æ®API
        api_keys_config = self.config_loader.load_config("api_keys.yaml")
        self.data_api = FinancialDataAPI(api_keys=api_keys_config)
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = LLMClient()
        
        # åˆå§‹åŒ–æ„å›¾è¯†åˆ«å™¨
        self.intent_recognizer = IntentRecognizer()
        
        # åˆå§‹åŒ–æ™ºèƒ½æç¤ºè¯æ„å»ºå™¨
        self.prompt_engine = PromptEngine()
        
        # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        self.data_processor = DataProcessor()

    def process_query(self, user_id: str, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å®Œæ•´æµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            # 1. æ„å›¾è¯†åˆ«å’ŒæŸ¥è¯¢åˆ†æ
            intent_analysis = self._analyze_query_intent(query)
            
            # 2. å¦‚æœæ˜¯ç®€å•æ—¶é—´æŸ¥è¯¢ï¼Œç›´æ¥è¿”å›
            if intent_analysis.get('is_simple_time_query'):
                response = self._handle_simple_time_query(query)
                self.session_manager.store_conversation(user_id, query, response)
                return response
            
            # 3. è·å–å†å²å¯¹è¯
            history = self.session_manager.get_conversation_history(user_id)
            history_tuples = [(turn['query'], turn['response']) for turn in history]
            
            # 4. æ ¹æ®æ„å›¾è·å–ç›¸å…³æ•°æ®
            relevant_data = self._get_intent_based_data(query, intent_analysis)
            
            # 5. æ„å»ºæ™ºèƒ½æç¤ºè¯
            full_prompt = self._construct_intelligent_prompt(
                query, history_tuples, relevant_data, intent_analysis
            )
            
            # 6. è°ƒç”¨å¤§æ¨¡å‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            response = self._call_llm_with_retry(full_prompt, intent_analysis)
            
            # 7. åå¤„ç†å’Œæ¥æºæ ‡æ³¨
            final_response = self._post_process_response(response, relevant_data, intent_analysis)
            
            # 8. å­˜å‚¨å¯¹è¯å†å²
            self.session_manager.store_conversation(user_id, query, final_response)
            
            return final_response
            
        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
            return self._get_fallback_response(query, e)

    def _analyze_query_intent(self, query: str) -> Dict:
        """æ·±åº¦æ„å›¾è¯†åˆ«å’Œåˆ†æ"""
        return self.intent_recognizer.analyze(query)

    def _get_intent_based_data(self, query: str, intent_analysis: Dict) -> Dict:
        """æ ¹æ®æ„å›¾è·å–ç›¸å…³æ•°æ®"""
        data_sources = {
            'knowledge_base': [],
            'real_time_data': {},
            'historical_context': {}
        }
        
        intent_type = intent_analysis.get('primary_intent', 'general')
        
        try:
            # 1. æ£€ç´¢çŸ¥è¯†åº“å†…å®¹
            if intent_analysis.get('needs_knowledge_base', True):
                data_sources['knowledge_base'] = self.knowledge_base.retrieve_relevant_chunks(
                    query, 
                    top_k=intent_analysis.get('knowledge_limit', 5)
                )
            
            # 2. è·å–å®æ—¶æ•°æ®
            if intent_analysis.get('needs_real_time_data', False):
                data_sources['real_time_data'] = self._get_enhanced_tool_data(query, intent_analysis)
            
            # 3. è·å–å†å²ä¸Šä¸‹æ–‡
            if intent_analysis.get('needs_historical_context', False):
                data_sources['historical_context'] = self._get_historical_context(intent_analysis)
                
        except Exception as e:
            logger.error(f"è·å–æ„å›¾æ•°æ®å¤±è´¥: {e}")
            data_sources['error'] = str(e)
            
        return data_sources

    def _get_enhanced_tool_data(self, query: str, intent_analysis: Dict) -> Dict:
        """å¢å¼ºçš„å·¥å…·æ•°æ®è·å–ï¼ˆåŸºäºæ„å›¾ï¼‰"""
        tool_data = {}
        intent_type = intent_analysis.get('primary_intent')
        
        try:
            if intent_type == 'market_news':
                # è·å–è´¢ç»æ–°é—»
                news_query = intent_analysis.get('news_keywords', 'è´¢ç»')
                tool_data["financial_news"] = self.data_api.get_financial_news(
                    query=news_query, 
                    limit=intent_analysis.get('news_limit', 8)
                )
                
            elif intent_type == 'stock_market':
                # è·å–å¸‚åœºæ¦‚å†µ
                tool_data["market_summary"] = self.data_api.get_today_market_summary()
                
                # è·å–ä¸»è¦æŒ‡æ•°
                indices = intent_analysis.get('target_indices', ['ä¸Šè¯æŒ‡æ•°', 'æ·±è¯æˆæŒ‡'])
                for index in indices:
                    tool_data[f"index_{index}"] = self.data_api.get_market_index(index)
                    
            elif intent_type == 'specific_stock':
                # è·å–ç‰¹å®šè‚¡ç¥¨æ•°æ®
                symbols = intent_analysis.get('target_symbols', [])
                for symbol in symbols:
                    tool_data[f"stock_{symbol}"] = self.data_api.get_stock_price(symbol)
                    # è·å–è¯¦ç»†åˆ†ææ•°æ®
                    tool_data[f"stock_detail_{symbol}"] = self.data_api.get_stock_intraday(symbol)
                    
            elif intent_type == 'economic_analysis':
                # è·å–ç»æµæ•°æ®
                indicators = intent_analysis.get('economic_indicators', ['GDP', 'CPI'])
                for indicator in indicators:
                    tool_data[f"economic_{indicator}"] = self.data_api.get_economic_data(indicator)
                    
        except Exception as e:
            logger.error(f"è·å–å¢å¼ºå·¥å…·æ•°æ®å¤±è´¥: {e}")
            tool_data['error'] = f"æ•°æ®è·å–å¤±è´¥: {str(e)}"
            
        return tool_data

    def _construct_intelligent_prompt(self, query: str, history: List[tuple], 
                                    data_sources: Dict, intent_analysis: Dict) -> str:
        """æ„å»ºæ™ºèƒ½æç¤ºè¯"""
        return self.prompt_engine.construct_prompt(
            query=query,
            history=history,
            data_sources=data_sources,
            intent_analysis=intent_analysis
        )

    def _call_llm_with_retry(self, prompt: str, intent_analysis: Dict, max_retries: int = 3) -> str:
        """å¸¦é‡è¯•æœºåˆ¶çš„LLMè°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                response = self.llm_client.generate(prompt)
                
                # éªŒè¯å“åº”è´¨é‡
                if self._validate_response_quality(response, intent_analysis):
                    return response
                else:
                    logger.warning(f"LLMå“åº”è´¨é‡ä¸ä½³ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•")
                    # ä¼˜åŒ–æç¤ºè¯åé‡è¯•
                    prompt = self._enhance_prompt_for_retry(prompt, attempt)
                    
            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{attempt+1}æ¬¡ï¼‰: {e}")
                if attempt == max_retries - 1:
                    raise e
                    
        return "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•ç”Ÿæˆæ»¡æ„çš„å›ç­”ã€‚"

    def _validate_response_quality(self, response: str, intent_analysis: Dict) -> bool:
        """éªŒè¯å“åº”è´¨é‡"""
        # åŸºç¡€éªŒè¯
        if not response or len(response.strip()) < 10:
            return False
            
        # æ„å›¾ç‰¹å®šéªŒè¯
        intent_type = intent_analysis.get('primary_intent')
        if intent_type == 'market_news' and 'æ–°é—»' not in response:
            return False
        elif intent_type == 'stock_market' and not any(keyword in response for keyword in ['æ¶¨', 'è·Œ', 'æŒ‡æ•°', 'ç‚¹']):
            return False
            
        return True

    def _post_process_response(self, response: str, data_sources: Dict, intent_analysis: Dict) -> str:
        """å“åº”åå¤„ç†"""
        # 1. æ•°æ®æ•´åˆå’ŒéªŒè¯
        processed_response = self.data_processor.integrate_data_into_response(
            response, data_sources, intent_analysis
        )
        
        # 2. æ·»åŠ æ¥æºå¼•ç”¨
        final_response = self._add_intelligent_citations(processed_response, data_sources)
        
        # 3. æ ¼å¼ä¼˜åŒ–
        final_response = self._format_response(final_response, intent_analysis)
        
        return final_response

    def _add_intelligent_citations(self, response: str, data_sources: Dict) -> str:
        """æ™ºèƒ½æ·»åŠ æ¥æºå¼•ç”¨"""
        citations = []
        
        # çŸ¥è¯†åº“å¼•ç”¨
        if data_sources.get('knowledge_base'):
            citations.append("ğŸ“š çŸ¥è¯†åº“å‚è€ƒ")
            
        # å®æ—¶æ•°æ®å¼•ç”¨
        if data_sources.get('real_time_data'):
            real_time_sources = []
            for key, data in data_sources['real_time_data'].items():
                if data and not isinstance(data, dict) or data.get('source'):
                    source = data.get('source', 'å®æ—¶æ•°æ®')
                    real_time_sources.append(source)
            
            if real_time_sources:
                citations.append(f"ğŸ“Š å®æ—¶æ•°æ®: {', '.join(set(real_time_sources))}")
        
        if citations:
            return response + "\n\n" + "\n".join(citations)
        
        return response

    def _handle_simple_time_query(self, query: str) -> str:
        """å¤„ç†ç®€å•æ—¶é—´æŸ¥è¯¢"""
        from utils.text_processing import insert_current_time
        return insert_current_time(query)

    def _format_response(self, response: str, intent_analysis: Dict) -> str:
        """æ ¼å¼åŒ–å“åº”è¾“å‡º"""
        # æ ¹æ®ä¸åŒæ„å›¾ç±»å‹è¿›è¡Œå“åº”æ ¼å¼åŒ–
        intent_type = intent_analysis.get('primary_intent')
        
        # å¸‚åœºåˆ†æç±»å“åº”æ ¼å¼
        if intent_type in ['market_news', 'stock_market', 'industry_analysis']:
            response = f"## {intent_type.replace('_', ' ').title()}åˆ†æ\n\n{response}"
        
        # æŠ•èµ„å»ºè®®ç±»å“åº”æ ¼å¼
        elif intent_type in ['investment_advice', 'risk_management']:
            response = f"## {intent_type.replace('_', ' ').title()}\n\nâš ï¸ **é£é™©æç¤º**ï¼šæŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…\n\n{response}"
        
        # è´¢åŠ¡è®¡ç®—ç±»å“åº”æ ¼å¼
        elif intent_type == 'financial_calculation':
            response = f"## è´¢åŠ¡è®¡ç®—ç»“æœ\n\n{response}"
        
        # åŸºç¡€ä¿¡æ¯æŸ¥è¯¢æ ¼å¼
        elif intent_type == 'general':
            response = f"## ä¿¡æ¯æŸ¥è¯¢ç»“æœ\n\n{response}"
        
        return response

    def _get_fallback_response(self, query: str, error: Exception) -> str:
        """é™çº§å“åº”å¤„ç†"""
        # åŸºç¡€ä¿¡æ¯æŸ¥è¯¢
        if any(keyword in query for keyword in ['æ—¶é—´', 'æ—¥æœŸ', 'ä»Šå¤©', 'ç°åœ¨']):
            return self._handle_simple_time_query(query)
            
        # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†æŠ€æœ¯é—®é¢˜ã€‚é”™è¯¯è¯¦æƒ…ï¼š{str(error)}"

    def close(self):
        """å…³é—­èµ„æºè¿æ¥"""
        self.knowledge_base.close_connections()