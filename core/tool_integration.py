# å·¥å…·è”åŠ¨ï¼ˆAPIè°ƒç”¨ä¸æ¥æºçº¦æŸï¼‰
import requests
import akshare as ak
import pandas as pd
from typing import Dict, Optional, List, Any
import logging
from datetime import datetime, timedelta
import json
import os
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FinancialDataAPI:
    def __init__(self, api_keys: Dict[str, Dict] = None):
        """åˆå§‹åŒ–APIå¯†é’¥å’Œé…ç½®"""
        self.api_keys = api_keys or {}
        self.akshare_enabled = True  # é»˜è®¤å¯ç”¨AkShare
        
    def get_stock_price(self, symbol: str) -> Optional[Dict]:
        """è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼ï¼ˆä¼˜å…ˆä½¿ç”¨AkShareï¼‰"""
        try:
            # ä¼˜å…ˆä½¿ç”¨AkShareè·å–Aè‚¡ã€æ¸¯è‚¡æ•°æ®
            akshare_result = self._get_stock_price_akshare(symbol)
            if akshare_result:
                return akshare_result
                
            # AkShareå¤±è´¥æ—¶ä½¿ç”¨Alpha Vantageï¼ˆç¾è‚¡ç­‰ï¼‰
            return self._get_stock_price_alpha_vantage(symbol)
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return None

    def _get_stock_price_akshare(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨AkShareè·å–è‚¡ç¥¨æ•°æ®"""
        try:
            if symbol.endswith('.SS') or symbol.endswith('.SZ'):
                # Aè‚¡æ•°æ®
                stock_code = symbol.replace('.SS', '').replace('.SZ', '')
                data = ak.stock_zh_a_spot_em()
                stock_data = data[data['ä»£ç '] == stock_code]
                
                if not stock_data.empty:
                    return {
                        'symbol': symbol,
                        'price': float(stock_data.iloc[0]['æœ€æ–°ä»·']),
                        'change': float(stock_data.iloc[0]['æ¶¨è·Œå¹…']),
                        'change_amount': float(stock_data.iloc[0]['æ¶¨è·Œé¢']),
                        'volume': int(stock_data.iloc[0]['æˆäº¤é‡']),
                        'amount': float(stock_data.iloc[0]['æˆäº¤é¢']),
                        'high': float(stock_data.iloc[0]['æœ€é«˜ä»·']),
                        'low': float(stock_data.iloc[0]['æœ€ä½ä»·']),
                        'open': float(stock_data.iloc[0]['ä»Šå¼€']),
                        'prev_close': float(stock_data.iloc[0]['æ˜¨æ”¶']),
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'akshare'
                    }
                    
            elif symbol.endswith('.HK'):
                # æ¸¯è‚¡æ•°æ®
                stock_code = symbol.replace('.HK', '')
                data = ak.stock_hk_spot_em()
                stock_data = data[data['ä»£ç '] == stock_code]
                
                if not stock_data.empty:
                    return {
                        'symbol': symbol,
                        'price': float(stock_data.iloc[0]['æœ€æ–°ä»·']),
                        'change': float(stock_data.iloc[0]['æ¶¨è·Œå¹…']),
                        'volume': int(stock_data.iloc[0]['æˆäº¤é‡']),
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'akshare'
                    }
                    
        except Exception as e:
            logger.warning(f"AkShareè·å–è‚¡ç¥¨æ•°æ®å¤±è´¥ {symbol}: {e}")
            
        return None

    def _get_stock_price_alpha_vantage(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Alpha Vantageè·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¸»è¦ç¾è‚¡ï¼‰"""
        try:
            if not self.api_keys.get("alpha_vantage"):
                return None
                
            alpha_config = self.api_keys["alpha_vantage"]
            params = {
                "function": "GLOBAL_QUOTE",
                "symbol": symbol.replace('.US', ''),
                "apikey": alpha_config["api_key"]
            }
            
            response = requests.get(alpha_config["base_url"], params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if "Global Quote" in data:
                quote = data["Global Quote"]
                return {
                    'symbol': symbol,
                    'price': float(quote.get("05. price", 0)),
                    'change': float(quote.get("10. change percent", "0%").replace('%', '')),
                    'change_amount': float(quote.get("09. change", 0)),
                    'volume': int(quote.get("06. volume", 0)),
                    'timestamp': quote.get("07. latest trading day", ""),
                    'source': 'alpha_vantage'
                }
                
        except Exception as e:
            logger.warning(f"Alpha Vantageè·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            
        return None

    def get_market_index(self, index_name: str) -> Optional[Dict]:
        """è·å–å¸‚åœºæŒ‡æ•°æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨AkShareï¼‰"""
        try:
            # ä½¿ç”¨AkShareè·å–Aè‚¡æŒ‡æ•°
            akshare_result = self._get_market_index_akshare(index_name)
            if akshare_result:
                return akshare_result
                
            # å¤‡ç”¨æ–¹æ¡ˆï¼šTwelveData
            return self._get_market_index_twelvedata(index_name)
        except Exception as e:
            logger.error(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return None

    def _get_market_index_akshare(self, index_name: str) -> Optional[Dict]:
        """ä½¿ç”¨AkShareè·å–æŒ‡æ•°æ•°æ®"""
        try:
            # è·å–Aè‚¡æŒ‡æ•°å®æ—¶æ•°æ®
            data = ak.stock_zh_index_spot()
            
            # æŒ‡æ•°ä»£ç æ˜ å°„
            index_mapping = {
                'ä¸Šè¯æŒ‡æ•°': '000001',
                'æ·±è¯æˆæŒ‡': '399001',
                'åˆ›ä¸šæ¿æŒ‡': '399006',
                'æ²ªæ·±300': '000300',
                'ä¸Šè¯50': '000016'
            }
            
            if index_name in index_mapping:
                index_code = index_mapping[index_name]
                index_data = data[data['ä»£ç '] == index_code]
                
                if not index_data.empty:
                    return {
                        'name': index_name,
                        'price': float(index_data.iloc[0]['æœ€æ–°ä»·']),
                        'change': float(index_data.iloc[0]['æ¶¨è·Œå¹…']),
                        'change_amount': float(index_data.iloc[0]['æ¶¨è·Œé¢']),
                        'volume': int(index_data.iloc[0]['æˆäº¤é‡']),
                        'amount': float(index_data.iloc[0]['æˆäº¤é¢']),
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'akshare'
                    }
                    
        except Exception as e:
            logger.warning(f"AkShareè·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            
        return None

    def _get_market_index_twelvedata(self, index_name: str) -> Optional[Dict]:
        """ä½¿ç”¨TwelveDataè·å–æŒ‡æ•°æ•°æ®"""
        try:
            if not self.api_keys.get("twelvedata"):
                return None
                
            twelve_config = self.api_keys["twelvedata"]
            params = {
                "symbol": index_name,
                "apikey": twelve_config["api_key"]
            }
            
            response = requests.get(f"{twelve_config['base_url']}/price", params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.warning(f"TwelveDataè·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return None

    def get_financial_news(self, query: str = "", limit: int = 10) -> Optional[Dict]:
        """è·å–è´¢ç»æ–°é—»ï¼ˆå¤šæ•°æ®æºï¼‰"""
        try:
            # ä¼˜å…ˆä½¿ç”¨AkShareè·å–è´¢ç»æ–°é—»
            akshare_news = self._get_news_akshare(limit)
            
            # å¤‡ç”¨ï¼šNewsAPI
            newsapi_news = self._get_news_newsapi(query, limit)
            
            # åˆå¹¶ç»“æœ
            all_articles = []
            if akshare_news and 'articles' in akshare_news:
                all_articles.extend(akshare_news['articles'])
            if newsapi_news and 'articles' in newsapi_news:
                all_articles.extend(newsapi_news['articles'])
                
            return {
                'articles': all_articles[:limit],
                'total': len(all_articles),
                'timestamp': datetime.now().isoformat(),
                'sources': ['akshare', 'newsapi']
            }
            
        except Exception as e:
            logger.error(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return None

    def _get_news_akshare(self, limit: int = 10) -> Optional[Dict]:
        """ä½¿ç”¨AkShareè·å–è´¢ç»æ–°é—»"""
        try:
            # è·å–è´¢ç»æ–°é—»
            news_data = ak.news_roll()
            
            articles = []
            for index, row in news_data.head(limit).iterrows():
                article = {
                    'title': row['æ–°é—»æ ‡é¢˜'],
                    'description': row['æ–°é—»å†…å®¹'][:200] + '...' if len(str(row['æ–°é—»å†…å®¹'])) > 200 else str(row['æ–°é—»å†…å®¹']),
                    'source': row['æ–°é—»æ¥æº'],
                    'publishedAt': row['å‘å¸ƒæ—¶é—´'],
                    'url': row['æ–°é—»é“¾æ¥']
                }
                articles.append(article)
                
            return {'articles': articles}
            
        except Exception as e:
            logger.warning(f"AkShareè·å–æ–°é—»å¤±è´¥: {e}")
            return None

    def _get_news_newsapi(self, query: str = "", limit: int = 5) -> Optional[Dict]:
        """ä½¿ç”¨NewsAPIè·å–è´¢ç»æ–°é—»"""
        try:
            if not self.api_keys.get("newsapi"):
                return None
                
            news_config = self.api_keys["newsapi"]
            params = {
                "q": query or "è´¢ç» è‚¡ç¥¨ ç»æµ",
                "language": "zh",
                "sortBy": "publishedAt",
                "pageSize": limit,
                "apiKey": news_config["api_key"]
            }
            
            response = requests.get(f"{news_config['base_url']}/everything", params=params, timeout=15)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.warning(f"NewsAPIè·å–æ–°é—»å¤±è´¥: {e}")
            return None

    def get_today_market_summary(self) -> Optional[Dict]:
        """è·å–ä»Šæ—¥å¸‚åœºæ¦‚å†µ"""
        try:
            summary = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'major_indices': {},
                'market_activity': {},
                'hot_sectors': []
            }
            
            # è·å–ä¸»è¦æŒ‡æ•°
            indices = ['ä¸Šè¯æŒ‡æ•°', 'æ·±è¯æˆæŒ‡', 'åˆ›ä¸šæ¿æŒ‡', 'æ²ªæ·±300']
            for index in indices:
                index_data = self.get_market_index(index)
                if index_data:
                    summary['major_indices'][index] = index_data
            
            # è·å–å¸‚åœºæ´»è·ƒåº¦
            try:
                market_activity = ak.stock_market_activity()
                summary['market_activity'] = {
                    'total_companies': market_activity.get('æ€»æ•°', 'N/A'),
                    'rising_companies': market_activity.get('ä¸Šæ¶¨å®¶æ•°', 'N/A'),
                    'falling_companies': market_activity.get('ä¸‹è·Œå®¶æ•°', 'N/A'),
                    'unchanged_companies': market_activity.get('å¹³ç›˜å®¶æ•°', 'N/A')
                }
            except Exception as e:
                logger.warning(f"è·å–å¸‚åœºæ´»è·ƒåº¦å¤±è´¥: {e}")
            
            # è·å–çƒ­é—¨æ¿å—
            try:
                hot_sectors = ak.stock_board_concept_spot_em()
                summary['hot_sectors'] = hot_sectors.head(5).to_dict('records')
            except Exception as e:
                logger.warning(f"è·å–çƒ­é—¨æ¿å—å¤±è´¥: {e}")
            
            return summary
            
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæ¦‚å†µå¤±è´¥: {e}")
            return None

    def get_stock_intraday(self, symbol: str, interval: str = "5min") -> Optional[Dict]:
        """è·å–è‚¡ç¥¨æ—¥å†…æ•°æ®"""
        try:
            # ä¼˜å…ˆä½¿ç”¨AkShare
            if symbol.endswith('.SS') or symbol.endswith('.SZ'):
                stock_code = symbol.replace('.SS', '').replace('.SZ', '')
                data = ak.stock_zh_a_hist_min_em(symbol=stock_code, period=interval)
                
                if not data.empty:
                    return {
                        'symbol': symbol,
                        'data': data.to_dict('records'),
                        'interval': interval,
                        'source': 'akshare'
                    }
                    
            # å¤‡ç”¨ï¼šAlpha Vantage
            return self._get_stock_intraday_alpha_vantage(symbol, interval)
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨æ—¥å†…æ•°æ®å¤±è´¥: {e}")
            return None

    def _get_stock_intraday_alpha_vantage(self, symbol: str, interval: str) -> Optional[Dict]:
        """ä½¿ç”¨Alpha Vantageè·å–æ—¥å†…æ•°æ®"""
        try:
            if not self.api_keys.get("alpha_vantage"):
                return None
                
            alpha_config = self.api_keys["alpha_vantage"]
            params = {
                "function": "TIME_SERIES_INTRADAY",
                "symbol": symbol.replace('.US', ''),
                "interval": interval,
                "apikey": alpha_config["api_key"]
            }
            
            response = requests.get(alpha_config["base_url"], params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.warning(f"Alpha Vantageè·å–æ—¥å†…æ•°æ®å¤±è´¥: {e}")
            return None

    def get_economic_data(self, indicator: str = "GDP") -> Optional[Dict]:
        """è·å–ç»æµæ•°æ®"""
        try:
            # ä½¿ç”¨AkShareè·å–å®è§‚ç»æµæ•°æ®
            if indicator == "GDP":
                data = ak.macro_china_gdp()
            elif indicator == "CPI":
                data = ak.macro_china_cpi()
            elif indicator == "PPI":
                data = ak.macro_china_ppi()
            else:
                return None
                
            return {
                'indicator': indicator,
                'data': data.to_dict('records'),
                'source': 'akshare',
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è·å–ç»æµæ•°æ®å¤±è´¥: {e}")
            return None

    def get_historical_data(self, symbol: str, interval: str = "1d", start_date: str = None, end_date: str = None) -> Optional[List[Dict]]:
        """è·å–è‚¡ç¥¨æˆ–ETFå†å²æ•°æ®ï¼ˆæ”¯æŒç¼“å­˜ï¼‰"""
        try:
            # å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼
            stock_code = symbol.replace('.SS', '').replace('.SZ', '').replace('.HK', '')
            logger.info(f"æ­£åœ¨å¤„ç†è‚¡ç¥¨ä»£ç : {symbol}ï¼Œå¤„ç†å: {stock_code}")
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºETFï¼ˆä»¥51ã€15ã€58å¼€å¤´çš„6ä½æ•°å­—ï¼‰
            is_etf = False
            if len(stock_code) == 6 and stock_code.isdigit():
                if stock_code.startswith(('51', '15', '58')):
                    is_etf = True
                    logger.info(f"è¯†åˆ«ä¸ºETF: {stock_code}")
            
            # è®¾ç½®ç¼“å­˜ç›®å½•å’Œæ–‡ä»¶å
            cache_dir = "../cache/stock_data"
            cache_file = os.path.join(cache_dir, f"{symbol}_{interval}.json")
            logger.info(f"ç¼“å­˜ç›®å½•: {cache_dir}ï¼Œç¼“å­˜æ–‡ä»¶: {cache_file}")
            
            # åˆ›å»ºç¼“å­˜ç›®å½•
            if not os.path.exists(cache_dir):
                os.makedirs(cache_dir)
                logger.info(f"åˆ›å»ºç¼“å­˜ç›®å½•: {cache_dir}")
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ7å¤©æœ‰æ•ˆæœŸï¼‰
            cache_valid = False
            if os.path.exists(cache_file):
                cache_time = os.path.getmtime(cache_file)
                if time.time() - cache_time < 7 * 24 * 3600:
                    cache_valid = True
                    logger.info(f"ç¼“å­˜æœ‰æ•ˆï¼Œå°†åŠ è½½ç¼“å­˜æ•°æ®")
            
            # åŠ è½½ç¼“å­˜æ•°æ®
            cached_data = []
            if cache_valid:
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cached_data = json.load(f)
                    logger.info(f"ä»ç¼“å­˜åŠ è½½äº† {len(cached_data)} æ¡å†å²æ•°æ®")
                    
                    # å¦‚æœæŒ‡å®šäº†æ—¥æœŸèŒƒå›´ï¼Œè¿‡æ»¤æ•°æ®
                    if start_date and end_date:
                        filtered_data = []
                        for item in cached_data:
                            if start_date <= item['date'] <= end_date:
                                filtered_data.append(item)
                        logger.info(f"æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤åå‰©ä½™ {len(filtered_data)} æ¡æ•°æ®")
                        return filtered_data
                    elif start_date:
                        filtered_data = []
                        for item in cached_data:
                            if item['date'] >= start_date:
                                filtered_data.append(item)
                        logger.info(f"æŒ‰èµ·å§‹æ—¥æœŸè¿‡æ»¤åå‰©ä½™ {len(filtered_data)} æ¡æ•°æ®")
                        return filtered_data
                    elif end_date:
                        filtered_data = []
                        for item in cached_data:
                            if item['date'] <= end_date:
                                filtered_data.append(item)
                        logger.info(f"æŒ‰ç»“æŸæ—¥æœŸè¿‡æ»¤åå‰©ä½™ {len(filtered_data)} æ¡æ•°æ®")
                        return filtered_data
                    return cached_data
                except Exception as e:
                    logger.error(f"åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
                    cache_valid = False
            
            # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œä»APIè·å–æ–°æ•°æ®
            logger.info(f"ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œå¼€å§‹ä»APIè·å–æ–°æ•°æ®")
            
            # AkShareå‘¨æœŸæ˜ å°„
            period_map = {
                "1d": "daily",
                "1w": "weekly",
                "1mo": "monthly"
            }
            ak_period = period_map.get(interval, "daily")
            logger.info(f"æ—¶é—´å‘¨æœŸæ˜ å°„: {interval} -> {ak_period}")
            
            # è·å–å†å²æ•°æ®
            data = None
            if is_etf:
                # ETFæ•°æ®
                logger.info(f"æ­£åœ¨è·å–ETF {stock_code} çš„å†å²æ•°æ®")
                try:
                    data = ak.fund_etf_hist_em(symbol=stock_code, period=ak_period)
                    logger.info(f"ETFæ•°æ®åˆ—å: {data.columns.tolist()}")
                except Exception as e:
                    logger.error(f"è·å–ETFæ•°æ®å¤±è´¥: {e}")
            else:
                # è‚¡ç¥¨æ•°æ®
                logger.info(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®")
                try:
                    if symbol.endswith('.SS') or symbol.endswith('.SZ'):
                        # Aè‚¡æ•°æ®
                        logger.info(f"è·å–Aè‚¡ {stock_code} çš„ {ak_period} æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
                        data = ak.stock_zh_a_hist(symbol=stock_code, period=ak_period)
                        logger.info(f"Aè‚¡æ•°æ®åˆ—å: {data.columns.tolist()}")
                        logger.info(f"Aè‚¡æ•°æ®å‰5è¡Œ: {data.head()}")
                    elif symbol.endswith('.HK'):
                        # æ¸¯è‚¡æ•°æ®
                        logger.info(f"è·å–æ¸¯è‚¡ {stock_code} çš„å†å²æ•°æ®")
                        try:
                            data = ak.stock_hk_hist(symbol=stock_code, period=ak_period)
                            logger.info(f"æ¸¯è‚¡æ•°æ®åˆ—å: {data.columns.tolist()}")
                        except Exception as e:
                            logger.error(f"æ¸¯è‚¡APIè°ƒç”¨å¤±è´¥: {e}")
                            return []
                except Exception as e:
                    logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            
            logger.info(f"è·å–åˆ°æ•°æ®å½¢çŠ¶: {data.shape if data is not None else 'None'}")
            
            if data is not None and not data.empty:
                # è½¬æ¢æ•°æ®æ ¼å¼
                historical_data = []
                
                # ETFæ•°æ®å­—æ®µæ˜ å°„ - é€‚é…ä¸åŒçš„å­—æ®µå
                if is_etf:
                    for _, row in data.iterrows():
                        # å°è¯•å¤šç§å­—æ®µåç»„åˆ
                        open_col = row.get('å¼€ç›˜ä»·', row.get('å¼€ç›˜', 0))
                        high_col = row.get('æœ€é«˜ä»·', row.get('æœ€é«˜', 0))
                        low_col = row.get('æœ€ä½ä»·', row.get('æœ€ä½', 0))
                        close_col = row.get('æ”¶ç›˜ä»·', row.get('æ”¶ç›˜', 0))
                        volume_col = row.get('æˆäº¤é‡', row.get('æˆäº¤', 0))
                        amount_col = row.get('æˆäº¤é¢', row.get('é‡‘é¢', 0))
                        change_col = row.get('æ¶¨è·Œå¹…', row.get('æ¶¨è·Œ', 0))
                        
                        # å¤„ç†æ—¥æœŸå­—æ®µ
                        date_value = row.get('æ—¥æœŸ', '')
                        if hasattr(date_value, 'strftime'):
                            date_str = date_value.strftime('%Y-%m-%d')
                        else:
                            date_str = str(date_value)
                        
                        historical_data.append({
                            'date': date_str,
                            'open': float(open_col),
                            'high': float(high_col),
                            'low': float(low_col),
                            'close': float(close_col),
                            'volume': int(volume_col) if volume_col != '-' else 0,
                            'amount': float(amount_col) if amount_col != '-' else 0,
                            'change': float(change_col) if change_col != '-' else 0,
                            'symbol': symbol
                        })
                # è‚¡ç¥¨æ•°æ®å­—æ®µæ˜ å°„
                else:
                    for _, row in data.iterrows():
                        # å¤„ç†æ—¥æœŸå­—æ®µ
                        date_value = row.get('æ—¥æœŸ', '')
                        if hasattr(date_value, 'strftime'):
                            date_str = date_value.strftime('%Y-%m-%d')
                        else:
                            date_str = str(date_value)
                        
                        historical_data.append({
                            'date': date_str,
                            'open': float(row.get('å¼€ç›˜', 0)),
                            'high': float(row.get('æœ€é«˜', 0)),
                            'low': float(row.get('æœ€ä½', 0)),
                            'close': float(row.get('æ”¶ç›˜', 0)),
                            'volume': int(row.get('æˆäº¤é‡', 0)),
                            'amount': float(row.get('æˆäº¤é¢', 0)),
                            'change': float(row.get('æ¶¨è·Œå¹…', 0)),
                            'symbol': symbol
                        })
                
                logger.info(f"è½¬æ¢åè·å–åˆ° {len(historical_data)} æ¡å†å²æ•°æ®")
                
                # ä¿å­˜åˆ°ç¼“å­˜
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(historical_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"å†å²æ•°æ®å·²ä¿å­˜åˆ°ç¼“å­˜: {cache_file}")
                except Exception as e:
                    logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
                
                return historical_data
            else:
                logger.warning(f"æœªè·å–åˆ°å†å²æ•°æ®: {symbol}")
                return []
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None


# è¾…åŠ©å‡½æ•°éƒ¨åˆ†
def add_source_citations(response: str, sources: List[Dict], kb) -> str:
    """ä¸ºå›ç­”æ·»åŠ æ¥æºå¼•ç”¨æ ‡æ³¨"""
    if not sources:
        return response

    # æå–æ¥æºä¿¡æ¯
    source_info = []
    for i, source in enumerate(sources, 1):
        # å¤„ç†çŸ¥è¯†åº“æ¥æº
        if hasattr(source, 'get') and source.get('document_id'):
            doc_id = source.get("document_id")
            url = kb.get_url_from_doc_id(doc_id) if hasattr(kb, 'get_url_from_doc_id') else f"æ–‡æ¡£ID: {doc_id}"
            source_info.append(f"[{i}] çŸ¥è¯†åº“: {url}")
        
        # å¤„ç†APIæ•°æ®æ¥æº
        elif hasattr(source, 'get') and source.get('source'):
            source_type = source.get('source', 'æœªçŸ¥æ¥æº')
            timestamp = source.get('timestamp', '')
            source_info.append(f"[{i}] {source_type}æ•°æ®: {timestamp}")

    # æ·»åŠ å¼•ç”¨æ ‡æ³¨
    if source_info:
        citation_text = "\n\nğŸ“š æ•°æ®æ¥æº:\n" + "\n".join(source_info)
        return response + citation_text
    
    return response


# æ–°å¢å·¥å…·å‡½æ•°
def validate_api_keys(api_keys: Dict) -> Dict:
    """éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§"""
    valid_keys = {}
    
    for api_name, config in api_keys.items():
        if config.get('api_key') and config.get('api_key') != 'your_api_key_here':
            valid_keys[api_name] = config
        else:
            logger.warning(f"{api_name} APIå¯†é’¥æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
    
    return valid_keys


def format_financial_data(data: Dict, data_type: str) -> str:
    """æ ¼å¼åŒ–é‡‘èæ•°æ®ç”¨äºæ˜¾ç¤º"""
    if not data:
        return "æš‚æ— æ•°æ®"
    
    try:
        if data_type == "stock":
            return f"""ğŸ“Š è‚¡ç¥¨æ•°æ®: {data.get('symbol', 'N/A')}
ğŸ’° å½“å‰ä»·æ ¼: {data.get('price', 'N/A')} 
ğŸ“ˆ æ¶¨è·Œå¹…: {data.get('change', 'N/A')}%
ğŸ“Š æˆäº¤é‡: {data.get('volume', 'N/A')}
â° æ›´æ–°æ—¶é—´: {data.get('timestamp', 'N/A')}"""
        
        elif data_type == "market":
            return f"""ğŸ¦ å¸‚åœºæ¦‚å†µ
ä¸»è¦æŒ‡æ•°è¡¨ç°:
{chr(10).join([f"- {name}: {info.get('price', 'N/A')} ({info.get('change', 'N/A')}%)" 
               for name, info in data.get('major_indices', {}).items()])}"""
        
        elif data_type == "news":
            articles = data.get('articles', [])
            return f"""ğŸ“° æœ€æ–°è´¢ç»æ–°é—» ({len(articles)}æ¡)
{chr(10).join([f'{i+1}. {article.get("title", "N/A")}' 
               for i, article in enumerate(articles[:3])])}"""
    
    except Exception as e:
        logger.error(f"æ ¼å¼åŒ–æ•°æ®å¤±è´¥: {e}")
    
    return "æ•°æ®æ ¼å¼å¼‚å¸¸"


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•AkShareåŠŸèƒ½
    api = FinancialDataAPI()
    
    # æµ‹è¯•Aè‚¡æ•°æ®
    stock_data = api.get_stock_price("600519.SS")
    print("è´µå·èŒ…å°æ•°æ®:", stock_data)
    
    # æµ‹è¯•æŒ‡æ•°æ•°æ®
    index_data = api.get_market_index("ä¸Šè¯æŒ‡æ•°")
    print("ä¸Šè¯æŒ‡æ•°æ•°æ®:", index_data)
    
    # æµ‹è¯•æ–°é—»æ•°æ®
    news_data = api.get_financial_news("è´¢ç»", 5)
    print("è´¢ç»æ–°é—»:", news_data)